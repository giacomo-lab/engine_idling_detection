{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is a title\n",
    "here is some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "#%%capture \n",
    "#hide output of this cell\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# Qua fatti una seconda var con il tuo path, cosi a seconda di chi lo sta usando mettiamo un hastag allinizio\n",
    "#tfrecord_path = 'C:/Users/matthias/Documents/projects/audioset_v1_embeddings/bal_train/--.tfrecord'\n",
    "tfrecord_path = '/Users/giacomo/Documents/lavoro/thunder_recognition/audioset_v1_embeddings/bal_train/--.tfrecord'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, inspect the raw TFR file structure to get an idea of how its built and it looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Iterate through the dataset and print the raw example data\n",
    "n = 1\n",
    "for record in dataset:\n",
    "    #print('record nr ', n)\n",
    "    example = tf.train.Example.FromString(record.numpy())\n",
    "    #print(example)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now iterate trough all files of the google AudioSet dataset. Using `filter_for_thunder()` we isolate all entries that have the thunder label and create a new file with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1444\n"
     ]
    }
   ],
   "source": [
    "# minimal example, file loop:\n",
    "\n",
    "#tfrecord_folder = 'C:/Users/matthias/Documents/projects/audioset_v1_embeddings/bal_train'\n",
    "tfrecord_folder = '/Users/giacomo/Documents/lavoro/thunder_recognition/audioset_v1_embeddings/bal_train/'\n",
    "\n",
    "tfrecord_files = [os.path.join(tfrecord_folder, f) for f in os.listdir(tfrecord_folder) if f.endswith('.tfrecord')]\n",
    "print(len(tfrecord_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TFRecord writer for the new file\n",
    "def filter_for_thunder(tfrecord_folder, new_file_path, value_to_check):\n",
    "    \"\"\"Parse trough a tfrecord file and search for entries related to one specific label, for example thunder (287),\n",
    "    when found, append the whole entrie to a new file.\n",
    "\n",
    "    Args:\n",
    "        old_file_path (str): path of the original TFRecord file\n",
    "        new_file_path (str): path to the newly created file containing only the selected entries\n",
    "        value_to_check (int): value of the label to use as filter \n",
    "        entries_list (empty list): an empty list to append matching entries to \n",
    "    \"\"\"   \n",
    "    \n",
    "    #create a list with all tfrecord files \n",
    "    tfrecord_files = [os.path.join(tfrecord_folder, f) for f in os.listdir(tfrecord_folder) if f.endswith('.tfrecord')]\n",
    "    entries_list = [] #empty list to append matching records\n",
    "    label_counter = 0 #counter to count the number of matching labels\n",
    "    \n",
    "    for file in tfrecord_files:\n",
    "          \n",
    "        for raw_record in tf.data.TFRecordDataset(file):\n",
    "            example = tf.train.Example()\n",
    "            example.ParseFromString(raw_record.numpy())\n",
    "\n",
    "            if value_to_check in example.features.feature['labels'].int64_list.value:\n",
    "                # If the value is found, write the example to the new TFRecord file\n",
    "                entries_list.append(raw_record.numpy())                        #not sure if the .numpy() is needed here, in case of problems delete!\n",
    "                label_counter += 1\n",
    "    \n",
    "    print('I found', label_counter, ' records for label', value_to_check)                    \n",
    "                        \n",
    "    with tf.io.TFRecordWriter(new_file_path) as writer:\n",
    "        for entry in entries_list:\n",
    "            writer.write(entry)                    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boom baby\n"
     ]
    }
   ],
   "source": [
    "if 34 in example.features.feature['labels'].int64_list.value: \n",
    "    print('boom baby')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 24  records for label 287\n"
     ]
    }
   ],
   "source": [
    "# use filter_for_thunder on the bal_training files \n",
    "new_filename = 'thunder_bal_training.tfrecord'\n",
    "\n",
    "filter_for_thunder(tfrecord_folder, new_filename, value_to_check=287)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 25  records for label 287\n"
     ]
    }
   ],
   "source": [
    "# use filter_for_thunder on the eval files \n",
    "#tfrecord_folder = 'C:/Users/matthias/Documents/projects/audioset_v1_embeddings/eval'\n",
    "tfrecord_folder = '/Users/giacomo/Documents/lavoro/thunder_recognition/audioset_v1_embeddings/eval/'\n",
    "new_filename = 'thunder_eval.tfrecord'\n",
    "\n",
    "filter_for_thunder(tfrecord_folder, new_filename, value_to_check=287)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use filter_for_thunder on the unbalanced training files \n",
    "tfrecord_folder = 'C:/Users/matthias/Documents/projects/audioset_v1_embeddings/unbal_train'\n",
    "new_filename = 'thunder_unbal_train.tfrecord'\n",
    "\n",
    "filter_for_thunder(tfrecord_folder, new_filename, value_to_check=287)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the newly created file if it containes the entries we expect\n",
    "dataset2 = tf.data.TFRecordDataset(new_filename)\n",
    "\n",
    "# Iterate through the dataset and print the raw example data\n",
    "for record in dataset2:\n",
    "    example = tf.train.Example.FromString(record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk code, keep for now, delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuovo approcio da stack overflow: https://stackoverflow.com/questions/65007191/how-to-read-decode-tfrecords-file-see-the-images-inside-and-do-augmentation\n",
    "# questo funyiona un pó meglio, si riescono ad accedere le singole entry. Sembra che alla fine file \n",
    "# TFRecord siano dizionari di dizionari di dizionari o qualcosa del genere. \n",
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "\n",
    "val = 1\n",
    "info = {}\n",
    "\n",
    "\n",
    "for i, raw_record in enumerate(dataset): # keeping at a minimal example of 3, remove for actual code\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    \n",
    "    # Questa parte qua fa il check per vedere se trova entries con thunder (287)\n",
    "    if 'labels' in example.features.feature:\n",
    "        label_values = example.features.feature['labels'].int64_list.value\n",
    "        if 399 in label_values:\n",
    "            print('THUNDEEEEERRRRR')\n",
    "            print(example)\n",
    "    \n",
    "    \n",
    "\"\"\"     for k, v in example.features.feature.items():\n",
    "        if k == 'labels':\n",
    "            #print(k, v, 'NEXT')\n",
    "            info[k] = v\n",
    "            \n",
    "            val += 1 \"\"\"\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\"\"\" print('INFO: \\n', info) \"\"\"\n",
    "#for n, m in info.items():\n",
    " #   if 287 in m:\n",
    "  #      print('THUNDEERRRRRR')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qua faccio un check per capire il data type del feature labels, perché piú avanti mi crea problemi\n",
    "# Define a parsing function to extract and decode the data\n",
    "## Boh sto qua semplicemente restituisce il data type specificato su tf.io.VarLenFeature(tf.int64), \n",
    "## e non il data type reale. Anche cambiare la parte 'features/feature/video_id' non ha nessun effetto\n",
    "\n",
    "\n",
    "def parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'features/feature/video_id': tf.io.VarLenFeature(tf.int64),\n",
    "        # Add other features and their types based on your TFRecord structure\n",
    "    }\n",
    "\n",
    "    # Parse the example\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # Get the 'labels' feature\n",
    "    labels = example['features/feature/video_id']\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Map the parsing function to the dataset\n",
    "parsed_data = dataset.map(parse_function)\n",
    "\n",
    "# Print the data type of the 'labels' feature\n",
    "for labels in parsed_data:\n",
    "    dtype = labels.values.dtype\n",
    "    print(f'Data Type of \"labels\" Feature: {dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and explore TFRecord files. \n",
    "Goal is to filter them in order to only keep files containing a certain label, like thunder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Questo approcio é quello che mi da chatGTP, che peró per me non funziona, le entry che mi ritorna sono vuote. \n",
    "# Qua poi in teoria volgio leggere i label (e solo quelli) in modo che piú avanti si possano filtrare i file che contengono il label thunder (287,/m/0ngt1)\n",
    "# La lista dei vari label si puó trovare nel file csv che ho caricato\n",
    "\n",
    "# Define a parsing function to extract and decode the data\n",
    "def parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'features/feature/': tf.io.VarLenFeature(tf.float32),\n",
    "        # Add other features and their types based on your TFRecord structure\n",
    "    }\n",
    "\n",
    "    # Parse the example\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # Decode the 'labels' feature\n",
    "    labels = tf.sparse.to_dense(example['features/feature/'])\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Map the parsing function to the dataset and iterate through the records\n",
    "for labels in dataset.map(parse_function):\n",
    "    # Print the 'labels' feature\n",
    "    print(f'time: {labels.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = 'C:/Users/matthias/Documents/projects/audioset_v1_embeddings/bal_train/-0.tfrecord'\n",
    "\n",
    "# tfrecord_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "\n",
    "# Define a parsing function to extract and decode the data\n",
    "def parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'context/feature/video_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'context/feature/start_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'context/feature/end_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'context/feature/labels': tf.io.VarLenFeature(tf.int64),\n",
    "        'feature_lists/feature_list/audio_embedding': tf.io.VarLenFeature(tf.string),\n",
    "        # Define other features and their types based on your TFRecord structure\n",
    "    }\n",
    "    \n",
    "    # Parse the example\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # If 'end_time_seconds' may not be present in all records, use allow_missing=True\n",
    "    if 'context/feature/end_time_seconds' in example:\n",
    "        end_time_seconds = example['context/feature/end_time_seconds']\n",
    "    else:\n",
    "        end_time_seconds = 0.0  # Provide a default value\n",
    "    \n",
    "    \n",
    "    # Decode the VarLenFeatures\n",
    "    example['context/feature/labels'] = tf.sparse.to_dense(example['context/feature/labels'], default_value=0)\n",
    "    example['feature_lists/feature_list/audio_embedding'] = tf.sparse.to_dense(example['feature_lists/feature_list/audio_embedding'], default_value='b')\n",
    "    \n",
    "    return example\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Map the parsing function to the dataset and iterate through the records\n",
    "for record in dataset.map(parse_function):\n",
    "    video_id = tf.strings.decode(record['context/feature/video_id'], 'utf-8')\n",
    "    start_time_seconds = tf.make_ndarray(record['context/feature/start_time_seconds'])[0]\n",
    "    end_time_seconds = tf.make_ndarray(record['context/feature/end_time_seconds'])[0]\n",
    "    labels = tf.make_ndarray(record['context/feature/labels'])\n",
    "    audio_embedding = record['feature_lists/feature_list/audio_embedding']\n",
    "    \n",
    "    print(f'Video ID: {video_id}')\n",
    "    print(f'Start Time (seconds): {start_time_seconds}')\n",
    "    print(f'End Time (seconds): {end_time_seconds}')\n",
    "    print(f'Labels: {labels}')\n",
    "    print(f'Audio Embedding: {audio_embedding}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thunder_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
