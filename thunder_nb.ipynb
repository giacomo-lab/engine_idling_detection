{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is a title\n",
    "here is some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "#%%capture \n",
    "#hide output of this cell\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# Qua fatti una seconda var con il tuo path, cosi a seconda di chi lo sta usando mettiamo un hastag allinizio\n",
    "tfrecord_path = 'C:/Users/matthias/Documents/projects/audioset_v1_embeddings/bal_train/--.tfrecord'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, inspect the raw TFR file structure to get an idea of how its built and it looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 40.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 399\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 30.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"--cB2ZVjpnA\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      " 1\n",
      "features {\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 40.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 451\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 30.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"--PJHxphWEs\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      " 1\n",
      "features {\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 40.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 27\n",
      "        value: 466\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 30.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"--ekDLDTUXA\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      " 1\n",
      "features {\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 10.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 95\n",
      "        value: 137\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"--aE2O5G5WE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      " 1\n",
      "features {\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 210.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 427\n",
      "        value: 431\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 200.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"--aaILOrkII\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      " 1\n",
      "features {\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 60.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 375\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 50.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"--ZhevVpy1s\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      " 1\n",
      "features {\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 40.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 32\n",
      "        value: 34\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 30.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"--aO5cdqSAg\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Iterate through the dataset and print the raw example data\n",
    "for record in dataset:\n",
    "    n = 1\n",
    "    example = tf.train.Example.FromString(record.numpy())\n",
    "    print(example, n)\n",
    "    n +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type of \"labels\" Feature: <dtype: 'int64'>\n",
      "Data Type of \"labels\" Feature: <dtype: 'int64'>\n",
      "Data Type of \"labels\" Feature: <dtype: 'int64'>\n",
      "Data Type of \"labels\" Feature: <dtype: 'int64'>\n",
      "Data Type of \"labels\" Feature: <dtype: 'int64'>\n",
      "Data Type of \"labels\" Feature: <dtype: 'int64'>\n",
      "Data Type of \"labels\" Feature: <dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "# Qua faccio un check per capire il data type del feature labels, perché piú avanti mi crea problemi\n",
    "# Define a parsing function to extract and decode the data\n",
    "## Boh sto qua semplicemente restituisce il data type specificato su tf.io.VarLenFeature(tf.int64), \n",
    "## e non il data type reale. Anche cambiare la parte 'features/feature/video_id' non ha nessun effetto\n",
    "\n",
    "\n",
    "def parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'features/feature/video_id': tf.io.VarLenFeature(tf.int64),\n",
    "        # Add other features and their types based on your TFRecord structure\n",
    "    }\n",
    "\n",
    "    # Parse the example\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # Get the 'labels' feature\n",
    "    labels = example['features/feature/video_id']\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Map the parsing function to the dataset\n",
    "parsed_data = dataset.map(parse_function)\n",
    "\n",
    "# Print the data type of the 'labels' feature\n",
    "for labels in parsed_data:\n",
    "    dtype = labels.values.dtype\n",
    "    print(f'Data Type of \"labels\" Feature: {dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels int64_list {\n",
      "  value: 399\n",
      "}\n",
      " NEXT\n",
      "labels int64_list {\n",
      "  value: 0\n",
      "  value: 451\n",
      "}\n",
      " NEXT\n",
      "labels int64_list {\n",
      "  value: 27\n",
      "  value: 466\n",
      "}\n",
      " NEXT\n",
      "INFO: \n",
      " {'labels': int64_list {\n",
      "  value: 27\n",
      "  value: 466\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Nuovo approcio da stack overflow: https://stackoverflow.com/questions/65007191/how-to-read-decode-tfrecords-file-see-the-images-inside-and-do-augmentation\n",
    "# questo funyiona un pó meglio, si riescono ad accedere le singole entry. Sembra che alla fine file \n",
    "# TFRecord siano dizionari di dizionari di dizionari o qualcosa del genere. \n",
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "for i, raw_record in enumerate(dataset.take(3)): # keeping at a minimal example of 3, remove for act code\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    info = {}\n",
    "    for k, v in example.features.feature.items():\n",
    "        if k == 'labels':\n",
    "            print(k, v, 'NEXT')\n",
    "            info[k] = v\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('INFO: \\n', info)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and explore TFRecord files. \n",
    "Goal is to filter them in order to only keep files containing a certain label, like thunder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: []\n",
      "time: []\n",
      "time: []\n",
      "time: []\n",
      "time: []\n",
      "time: []\n",
      "time: []\n"
     ]
    }
   ],
   "source": [
    "# Qua poi in teoria volgio leggere i label (e solo quelli) in modo che piú avanti si possano filtrare i file che contengono il label thunder (287,/m/0ngt1)\n",
    "# La lista dei vari label si puó trovare nel file csv che ho caricato\n",
    "\n",
    "# Define a parsing function to extract and decode the data\n",
    "def parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'features/feature/': tf.io.VarLenFeature(tf.float32),\n",
    "        # Add other features and their types based on your TFRecord structure\n",
    "    }\n",
    "\n",
    "    # Parse the example\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # Decode the 'labels' feature\n",
    "    labels = tf.sparse.to_dense(example['features/feature/'])\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Map the parsing function to the dataset and iterate through the records\n",
    "for labels in dataset.map(parse_function):\n",
    "    # Print the 'labels' feature\n",
    "    print(f'time: {labels.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_5_device_/job:localhost/replica:0/task:0/device:CPU:0}} Feature: context/feature/end_time_seconds (data type: float) is required but could not be found.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matthias\\Documents\\Projects\\thunder_recognition\\thunder_nb.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matthias/Documents/Projects/thunder_recognition/thunder_nb.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mTFRecordDataset(tfrecord_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matthias/Documents/Projects/thunder_recognition/thunder_nb.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Map the parsing function to the dataset and iterate through the records\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/matthias/Documents/Projects/thunder_recognition/thunder_nb.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m record \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39mmap(parse_function):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matthias/Documents/Projects/thunder_recognition/thunder_nb.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     video_id \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mstrings\u001b[39m.\u001b[39mdecode(record[\u001b[39m'\u001b[39m\u001b[39mcontext/feature/video_id\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matthias/Documents/Projects/thunder_recognition/thunder_nb.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     start_time_seconds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmake_ndarray(record[\u001b[39m'\u001b[39m\u001b[39mcontext/feature/start_time_seconds\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\matthias\\miniconda3\\envs\\thunder2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[0;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matthias\\miniconda3\\envs\\thunder2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[0;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[0;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[0;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matthias\\miniconda3\\envs\\thunder2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3014\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 3016\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   3017\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[0;32m   3018\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matthias\\miniconda3\\envs\\thunder2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_5_device_/job:localhost/replica:0/task:0/device:CPU:0}} Feature: context/feature/end_time_seconds (data type: float) is required but could not be found.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "tfrecord_path = 'C:/Users/matthias/Documents/projects/audioset_v1_embeddings/bal_train/-0.tfrecord'\n",
    "\n",
    "# tfrecord_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "\n",
    "# Define a parsing function to extract and decode the data\n",
    "def parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'context/feature/video_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'context/feature/start_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'context/feature/end_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'context/feature/labels': tf.io.VarLenFeature(tf.int64),\n",
    "        'feature_lists/feature_list/audio_embedding': tf.io.VarLenFeature(tf.string),\n",
    "        # Define other features and their types based on your TFRecord structure\n",
    "    }\n",
    "    \n",
    "    # Parse the example\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # If 'end_time_seconds' may not be present in all records, use allow_missing=True\n",
    "    if 'context/feature/end_time_seconds' in example:\n",
    "        end_time_seconds = example['context/feature/end_time_seconds']\n",
    "    else:\n",
    "        end_time_seconds = 0.0  # Provide a default value\n",
    "    \n",
    "    \n",
    "    # Decode the VarLenFeatures\n",
    "    example['context/feature/labels'] = tf.sparse.to_dense(example['context/feature/labels'], default_value=0)\n",
    "    example['feature_lists/feature_list/audio_embedding'] = tf.sparse.to_dense(example['feature_lists/feature_list/audio_embedding'], default_value='b')\n",
    "    \n",
    "    return example\n",
    "\n",
    "# Create a TFRecordDataset\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Map the parsing function to the dataset and iterate through the records\n",
    "for record in dataset.map(parse_function):\n",
    "    video_id = tf.strings.decode(record['context/feature/video_id'], 'utf-8')\n",
    "    start_time_seconds = tf.make_ndarray(record['context/feature/start_time_seconds'])[0]\n",
    "    end_time_seconds = tf.make_ndarray(record['context/feature/end_time_seconds'])[0]\n",
    "    labels = tf.make_ndarray(record['context/feature/labels'])\n",
    "    audio_embedding = record['feature_lists/feature_list/audio_embedding']\n",
    "    \n",
    "    print(f'Video ID: {video_id}')\n",
    "    print(f'Start Time (seconds): {start_time_seconds}')\n",
    "    print(f'End Time (seconds): {end_time_seconds}')\n",
    "    print(f'Labels: {labels}')\n",
    "    print(f'Audio Embedding: {audio_embedding}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thunder_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
